82% **********************************************************************
******* 4_Troubleshoot_Network *******************************************
**************************************************************************
-----------------------------------------------------------------------------


1. **Troubleshooting Test 1:** 
A simple 2 tier application is deployed in the "triton" namespace. It must display a green web page on success. 
Click on the app tab at the top of your terminal to view your application. It is currently failed. Troubleshoot and fix the issue. 
Stick to the given architecture. Use the same names and port numbers as given in the below architecture diagram. 
Feel free to edit, delete or recreate objects as necessary.

DB Service working?
WebApp Service working?

root@controlplane ~ ➜  kubectl get service -n triton 
NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
mysql         ClusterIP   10.103.199.64    <none>        3306/TCP         6m27s
web-service   NodePort    10.105.244.219   <none>        8080:30081/TCP   6m26s

root@controlplane ~ ➜  kubectl get pods -n triton 
NAME                           READY   STATUS              RESTARTS   AGE
mysql                          0/1     ContainerCreating   0          7m32s
webapp-mysql-d89894b4b-rnbrd   0/1     ContainerCreating   0          7m31s

root@controlplane ~ ➜  kubectl describe pods -n triton mysql 
Status:           Pending
IP:               
IPs:              <none>
    Host Port:      0/TCP
    State:          Waiting

Events:
  Type     Reason                  Age                     From               Message
  ----     ------                  ----                    ----               -------
  Warning  FailedCreatePodSandBox  7m56s                   kubelet            Failed to create pod sandbox: rpc error: 
code = Unknown desc = failed to setup network for sandbox "56b6019e8abd5b4e86cba872b5859b90c98692f1e83018c1be7d5c9736637881": 
plugin type="weave-net" name="weave" failed (add): unable to allocate IP address: 
Post "http://127.0.0.1:6784/ip/56b6019e8abd5b4e86cba872b5859b90c98692f1e83018c1be7d5c9736637881": dial tcp 127.0.0.1:6784: connect: connection refused

root@controlplane ~ ➜  kubectl get deployments.apps -n triton 
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
webapp-mysql   0/1     1            0           14m



Do the services in triton namespace have a valid endpoint? If they do, check the kube-proxy and the weave logs.
root@controlplane ~ ➜  cat mysql.yml 
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2025-01-14T07:31:35Z"
  name: mysql
  namespace: triton
  resourceVersion: "1556"
  uid: b2616243-6282-4e0c-92ff-da4a79e14935
spec:
  clusterIP: 10.103.199.64
  clusterIPs:
  - 10.103.199.64
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - port: 3306
    protocol: TCP
    targetPort: 3306
  selector:
    name: mysql
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}

root@controlplane ~ ➜  cat web-svc.yml 
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2025-01-14T07:31:36Z"
  name: web-service
  namespace: triton
  resourceVersion: "1576"
  uid: 6f7abb5d-c54b-4fdb-903d-918a61634524
spec:
  clusterIP: 10.105.244.219
  clusterIPs:
  - 10.105.244.219
  externalTrafficPolicy: Cluster
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - nodePort: 30081
    port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    name: webapp-mysql
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}

Does the cluster have a Network Addon installed?
Install Weave using the link: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network
For example: curl -L https://github.com/weaveworks/weave/releases/download/latest_release/weave-daemonset-k8s-1.11.yaml | kubectl apply -f -


root@controlplane ~ ➜  curl -L https://github.com/weaveworks/weave/releases/download/latest_release/weave-daemonset-k8s-1.11.yaml | kubectl apply -f -
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100  6183  100  6183    0     0  14310      0 --:--:-- --:--:-- --:--:-- 1296k
serviceaccount/weave-net created
clusterrole.rbac.authorization.k8s.io/weave-net created
clusterrolebinding.rbac.authorization.k8s.io/weave-net created
role.rbac.authorization.k8s.io/weave-net created
rolebinding.rbac.authorization.k8s.io/weave-net created
daemonset.apps/weave-net created


root@controlplane ~ ➜  kubectl get pods -n kube-system  | grep weave
weave-net-7547s                        2/2     Running   0          19s

root@controlplane ~ ➜  kubectl get deployments.apps -n triton 
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
webapp-mysql   1/1     1            1           22m

root@controlplane ~ ➜  kubectl get pods -n triton 
NAME                           READY   STATUS    RESTARTS   AGE
mysql                          1/1     Running   0          22m
webapp-mysql-d89894b4b-rnbrd   1/1     Running   0          22m

root@controlplane ~ ➜  kubectl get service -n triton 
NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
mysql         ClusterIP   10.103.199.64    <none>        3306/TCP         22m
web-service   NodePort    10.105.244.219   <none>        8080:30081/TCP   22m

root@controlplane ~ ➜  kubectl describe pods -n triton mysql
Status:           Running
IP:               10.32.0.1
IPs:
  IP:  10.32.0.1

root@controlplane ~ ➜  kubectl describe pods -n triton webapp-mysql-d89894b4b-rnbrd
Status:           Running
IP:               10.32.0.3
IPs:
  IP:           10.32.0.3

----------------------------
--- FLANNEL --- works too
----------------------------
root@controlplane ~ ➜  kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
root@controlplane ~ ➜  kubectl get pods -n kube-flannel 
NAME                    READY   STATUS    RESTARTS   AGE
kube-flannel-ds-qnxsd   1/1     Running   0          2m20s
root@controlplane ~ ➜  kubectl describe service -n triton web-service | grep -i ip
IP Family Policy:         SingleStack
IP Families:              IPv4
IP:                       10.109.62.253
IPs:                      10.109.62.253
----------------------------------------------------------------------------------------------------------------------------






2. **Troubleshooting Test 2:** 
The same 2 tier application is having issues again. It must display a green web page on success. 
Click on the app tab at the top of your terminal to view your application. It is currently failed. Troubleshoot and fix the issue.
Stick to the given architecture. Use the same names and port numbers as given in the below architecture diagram. 
Feel free to edit, delete or recreate objects as necessary.

root@controlplane ~ ✖ kubectl get pods -n kube-system  | grep proxy
kube-proxy-9fnmr                       0/1     CrashLoopBackOff   7 (78s ago)   12m


root@controlplane ~ ➜  kubectl describe pods -n kube-system kube-proxy-9fnmr 
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
Warning  BackOff    3m22s (x48 over 13m)  kubelet            
Back-off restarting failed container kube-proxy in pod kube-proxy-9fnmr_kube-system(d496ed3d-cbc4-4cf3-a315-d7ce69598c18)


root@controlplane ~ ➜  kubectl logs -n kube-system kube-proxy-9fnmr 
E0114 10:59:53.246933       1 run.go:74] "command failed" 
err="failed complete: open /var/lib/kube-proxy/configuration.conf: no such file or directory"

root@controlplane ~ ➜  kubectl get daemonsets.apps -n kube-system
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-proxy   1         1         0       1            0           kubernetes.io/os=linux   35m
weave-net    1         1         1       1            1           <none>                   31m


root@controlplane ~ ➜  kubectl get pod -n kube-system kube-proxy-9sj2d -oyaml > kproxy-pod.yml
root@controlplane ~ ✖ kubectl delete pod -n kube-system kube-proxy-mvqlt 
vi kproxy-pod.yml ---> change "- --config=/var/lib/kube-proxy/configuration.conf" ---to--- "- --config=/var/lib/kube-proxy/config.conf"
root@controlplane ~ ➜  kubectl create -f kproxy-pod.yml  ---> pod/kube-proxy-9sj2d created
root@controlplane ~ ➜  kubectl get pod -n kube-system | grep kube-proxy
kube-proxy-cb26q                       0/1     CrashLoopBackOff   5 (104s ago)


--- HINT ---
There seems to be an issue with the Service Proxy. Inspect and Fix the kube-proxy daemonset.
Check logs of the kube-proxy pod. It appears that the daemonset is using a wrong configuration file.
Compare the configuration file used in the daemonset with the configmap for kube-proxy.
Edit the kube-proxy daemonset to correct the configuration file using kubectl -n kube-system edit ds kube-proxy.


root@controlplane ~ ➜  kubectl get daemonsets.apps -n kube-system 
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-proxy   1         1         0       1            0           kubernetes.io/os=linux   24s

# root@controlplane ~ ✖ kubectl get pods -n kube-system kube-proxy-srhwn -oyaml > kPrPod.yml
root@controlplane ~ ➜  kubectl get daemonsets.apps -n kube-system kube-proxy -oyaml > ds.yml
Change "configuration.conf" to "config.conf" ---> delete DS, create DS


----------------------------------------------------------------------------------------------------------------------------
