82% **********************************************************************
******* 4_Troubleshoot_Network *******************************************
**************************************************************************
-----------------------------------------------------------------------------



2. **Troubleshooting Test 2:** (---- kube-proxy-26sw4    0/1     Error    ---)
The same 2 tier application is having issues again. It must display a green web page on success. 
Click on the app tab at the top of your terminal to view your application. It is currently failed. Troubleshoot and fix the issue.
Stick to the given architecture. Use the same names and port numbers as given in the below architecture diagram. 
Feel free to edit, delete or recreate objects as necessary.

root@controlplane ~ ✖ kubectl get pods -n kube-system  | grep proxy
kube-proxy-9fnmr                       0/1     CrashLoopBackOff   7 (78s ago)   12m


root@controlplane ~ ➜  kubectl describe pods -n kube-system kube-proxy-26sw4 
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
Warning  BackOff    3m22s (x48 over 13m)  kubelet            
Back-off restarting failed container kube-proxy in pod kube-proxy-9fnmr_kube-system(d496ed3d-cbc4-4cf3-a315-d7ce69598c18)


root@controlplane ~ ➜  kubectl logs -n kube-system kube-proxy-26sw4  
E0114 10:59:53.246933       1 run.go:74] "command failed" 
err="failed complete: open /var/lib/kube-proxy/configuration.conf: no such file or directory"

root@controlplane ~ ➜  kubectl get daemonsets.apps -n kube-system
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-proxy   1         1         0       1            0           kubernetes.io/os=linux   35m
weave-net    1         1         1       1            1           <none>                   31m


root@controlplane ~ ➜  kubectl get pod -n kube-system kube-proxy-26sw4 -oyaml > kproxy-pod.yml
root@controlplane ~ ✖ kubectl delete pod -n kube-system kube-proxy-mvqlt 
vi kproxy-pod.yml ---> change "- --config=/var/lib/kube-proxy/configuration.conf" ---to--- "- --config=/var/lib/kube-proxy/config.conf"
root@controlplane ~ ➜  kubectl create -f kproxy-pod.yml  ---> pod/kube-proxy-9sj2d created
root@controlplane ~ ➜  kubectl get pod -n kube-system | grep kube-proxy
kube-proxy-cb26q                       0/1     CrashLoopBackOff   5 (104s ago)



Pod kube-proxy-26sw4 Conf file                /var/lib/kube-proxy/configuration.conf
Pod kube-proxy-26sw4 Describe        --config=/var/lib/kube-proxy/configuration.conf
DaemonSet Conf file                  --config=/var/lib/kube-proxy/configuration.conf  
ConfigMap kube-proxy Describe          data:  config.conf    #<----------------------------------------------


  root@controlplane ~ ➜  kubectl get ds -n kube-system
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   46m
weave-net    1         1         1       1            1           <none>                   53m

root@controlplane ~ ➜  kubectl get  pod -n kube-system | grep kube-proxy
kube-proxy-kjp4z                       1/1     Running   3 (53s ago)   7m29s

root@controlplane ~ ➜  kubectl get  pod -n kube-system 
NAME                                   READY   STATUS    RESTARTS      AGE
coredns-66bc5c9577-lbt9h               1/1     Running   0             54m
coredns-66bc5c9577-sbfkp               1/1     Running   0             54m
etcd-controlplane                      1/1     Running   0             54m
kube-apiserver-controlplane            1/1     Running   0             54m
kube-controller-manager-controlplane   1/1     Running   0             54m
kube-proxy-kjp4z                       1/1     Running   3 (59s ago)   7m35s
kube-scheduler-controlplane            1/1     Running   0             54m
weave-net-qgj6x                        2/2     Running   0             49m



--- HINT ---
There seems to be an issue with the Service Proxy. Inspect and Fix the kube-proxy daemonset.
Check logs of the kube-proxy pod. It appears that the daemonset is using a wrong configuration file.
Compare the configuration file used in the daemonset with the configmap for kube-proxy.
Edit the kube-proxy daemonset to correct the configuration file using kubectl -n kube-system edit ds kube-proxy.


root@controlplane ~ ➜  kubectl get daemonsets.apps -n kube-system 
NAME         DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-proxy   1         1         0       1            0           kubernetes.io/os=linux   24s



----------------------------------------------------------------------------------------------------------------------------
Solution:
Check the pods in all namespaces using k get pods -A command.
You will find the app Pods are running , however the kube-proxy is having issues.

root@controlplane ~ ➜  k get pods -A
NAMESPACE     NAME                                   READY   STATUS             RESTARTS      AGE
kube-system   coredns-668d6bf9bc-4nbdj               1/1     Running            0             3m45s
kube-system   coredns-668d6bf9bc-zcddz               1/1     Running            0             3m45s
kube-system   etcd-controlplane                      1/1     Running            0             3m50s
kube-system   kube-apiserver-controlplane            1/1     Running            0             3m52s
kube-system   kube-controller-manager-controlplane   1/1     Running            0             3m50s
kube-system   kube-proxy-wx5f9                       0/1     CrashLoopBackOff   2 (18s ago)   38s
kube-system   kube-scheduler-controlplane            1/1     Running            0             3m50s
kube-flannel  kube-flannel-ds-p72qf                  1/1     Running            0             117s
triton        mysql                                  1/1     Running            0             38s
triton        webapp-mysql-7bd5857746-wwfhz          1/1     Running            0             38s
Get the logs using k logs -n kube-system <POD_NAME> command .
root@controlplane ~ ➜  k logs -n kube-system kube-proxy-wx5f9
[E0613 09:45:18.840160       1 run.go:74] "command failed" err="failed complete: open /var/lib/kube-proxy/configuration.conf: no such file or directory"
This means kube-proxy is failing because it cannot find its configuration file at /var/lib/kube-proxy/configuration.conf.

Describe the failed pod using command k describe -n kube-system pod <POD_NAME>
root@controlplane ~ ➜  k describe -n kube-system pod kube-proxy-wx5f9
Name:                 kube-proxy-wx5f9
Namespace:            kube-system
...
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-gcxd6 (ro)
...
Volumes:
  kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
...
This confirms that kube-proxy expects its configuration to be mounted as a ConfigMap named kube-proxy into the /var/lib/kube-proxy directory.

Check the ConfigMap using command : k get configmap -n kube-system kube-proxy -o yaml
root@controlplane /var/lib/kube-proxy ➜  k get configmap -n kube-system kube-proxy -o yaml
apiVersion: v1
data:
  config.conf: |-
    apiVersion: kubeproxy.config.k8s.io/v1alpha1
    bindAddress: 0.0.0.0
    bindAddressHardFail: false
    clientConnection:
      acceptContentTypes: ""
      burst: 0
      contentType: ""
      kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
...
Check the Current configs of the Deamonset :
oot@controlplane /var/lib/kube-proxy ➜  kubectl -n kube-system describe ds kube-proxy
Name:           kube-proxy
Selector:       k8s-app=kube-proxy
...
  Containers:
   kube-proxy:
    Image:      registry.k8s.io/kube-proxy:v1.26.0
    Port:       <none>
    Host Port:  <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/configuration.conf
      --hostname-override=$(NODE_NAME)
    Environment:
      NODE_NAME:   (v1:spec.nodeName)
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
  Volumes:
   kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
...
Based on the logs (failed complete: open /var/lib/kube-proxy/configuration.conf: no such file or directory), 
the DaemonSet\'s --config argument points to configuration.conf, but the ConfigMap provides its main configuration under config.conf

Fix
We need to change the kube-proxy DaemonSet to point to the correct configuration file name that exists in the kube-proxy ConfigMap , which is : config.conf

Edit the DaemonSet:
kubectl -n kube-system edit ds kube-proxy
Find the command or args section.
command:
        - /usr/local/bin/kube-proxy
        - --config=/var/lib/kube-proxy/configuration.conf # <--- THIS IS THE LINE TO CHANGE
        - --hostname-override=$(NODE_NAME)
Change configuration.conf to config.conf
command:
        - /usr/local/bin/kube-proxy
        - --config=/var/lib/kube-proxy/config.conf # <--- CHANGED!
        - --hostname-override=$(NODE_NAME)
Monitor kube-proxy pod status and verify application connectivity.

k get pods -n kube-system -w