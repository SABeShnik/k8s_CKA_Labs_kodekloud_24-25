1. Lab Objective:
In this lab, you will install and configure the Vertical Pod Autoscaler (VPA) in your Kubernetes cluster. The lab will walk you through the installation of VPA using predefined manifests, cloning the VPA repository for advanced control, and deploying a sample application to see how VPA interacts with it. Additionally, you'll learn how to troubleshoot issues using VPA logs.
By the end of this lab, you should be able to:
Install VPA and its components (Recommender, Updater, Admission Controller) in a Kubernetes cluster
Understand the role of each VPA component and how they contribute to efficient resource management
Deploy a sample application to see how VPA recommends and adjusts resources for it
Troubleshoot resource-related issues in your application using logs generated by the VPA components, particularly the VPA Updater
This hands-on experience will give you the skills to manage pod resources dynamically in a production-grade Kubernetes environment, ensuring that applications run efficiently with the appropriate resource requests.

–¶–µ–ª—å –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç—ã:
–í —ç—Ç–æ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç–µ –≤—ã —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç–µ Vertical Pod Autoscaler (VPA) –≤ –≤–∞—à–µ–º –∫–ª–∞—Å—Ç–µ—Ä–µ Kubernetes. –í —Ö–æ–¥–µ —Ä–∞–±–æ—Ç—ã –≤—ã –ø—Ä–æ–π–¥–µ—Ç–µ —ç—Ç–∞–ø—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ VPA —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –º–∞–Ω–∏—Ñ–µ—Å—Ç–æ–≤, –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è VPA –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –∫–∞–∫ VPA –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç —Å –Ω–∏–º. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –≤—ã –Ω–∞—É—á–∏—Ç–µ—Å—å —É—Å—Ç—Ä–∞–Ω—è—Ç—å –Ω–µ–ø–æ–ª–∞–¥–∫–∏ —Å –ø–æ–º–æ—â—å—é –ª–æ–≥–æ–≤ VPA.
–ü–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —ç—Ç–æ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç—ã –≤—ã —Å–º–æ–∂–µ—Ç–µ:
–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å VPA –∏ –µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (Recommender, Updater, Admission Controller) –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ Kubernetes
–ü–æ–Ω—è—Ç—å —Ä–æ–ª—å –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ VPA –∏ —Ç–æ, –∫–∞–∫ –æ–Ω–∏ —Å–ø–æ—Å–æ–±—Å—Ç–≤—É—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–º—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–µ—Å—É—Ä—Å–∞–º–∏
–†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –ø—Ä–∏–º–µ—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å, –∫–∞–∫ VPA —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –¥–ª—è –Ω–µ–≥–æ —Ä–µ—Å—É—Ä—Å—ã
–£—Å—Ç—Ä–∞–Ω—è—Ç—å –Ω–µ–ø–æ–ª–∞–¥–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —Ä–µ—Å—É—Ä—Å–∞–º–∏ –≤ –≤–∞—à–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è –∂—É—Ä–Ω–∞–ª—ã, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ VPA, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, VPA Updater
–≠—Ç–æ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –¥–∞—Å—Ç –≤–∞–º –Ω–∞–≤—ã–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–∞–º–∏ –ø–æ–¥–æ–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π —Å—Ä–µ–¥–µ Kubernetes, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Ä–∞–±–æ—Ç—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏ –Ω–∞ —Ä–µ—Å—É—Ä—Å—ã.




2. We have prepared the required YAML files for you to deploy the Vertical Pod Autoscaler (VPA). Simply follow the steps below to apply the necessary configurations:
    Step 1: Install VPA Custom Resource Definitions (CRDs)
These CRDs allow Kubernetes to recognize the custom resources that VPA uses to function properly. To install them, run this command:
kubectl apply -f /root/vpa-crds.yml
    Step 2: Install VPA Role-Based Access Control (RBAC)
RBAC ensures that VPA has the appropriate permissions to operate within your Kubernetes cluster. To install the RBAC settings, run:
kubectl apply -f /root/vpa-rbac.yml
    By running these commands, the VPA will be successfully deployed to your cluster, ready to manage and adjust your pod resources dynamically.
------------------------------
–ú—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ YAML-—Ñ–∞–π–ª—ã –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è Vertical Pod Autoscaler (VPA). –ü—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
    –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ VPA (CRD)
–≠—Ç–∏ CRD –ø–æ–∑–≤–æ–ª—è—é—Ç Kubernetes —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Ä–µ—Å—É—Ä—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ VPA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã. –î–ª—è –∏—Ö —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –∫–æ–º–∞–Ω–¥—É:
kubectl apply -f /root/vpa-crds.yml
    –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–æ–ª–µ–π (RBAC) VPA
RBAC –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ VPA –∏–º–µ–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ –≤–∞—à–µ–º –∫–ª–∞—Å—Ç–µ—Ä–µ Kubernetes. –î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ RBAC –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:
kubectl apply -f /root/vpa-rbac.yml
    –í—ã–ø–æ–ª–Ω–∏–≤ —ç—Ç–∏ –∫–æ–º–∞–Ω–¥—ã, VPA –±—É–¥–µ—Ç —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç –≤ –≤–∞—à–µ–º –∫–ª–∞—Å—Ç–µ—Ä–µ –∏ –≥–æ—Ç–æ–≤ –∫ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–º—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –≤–∞—à–∏—Ö –ø–æ–¥–æ–≤.


controlplane ~ ‚ûú  kubectl apply -f /root/vpa-crds.yml
customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalercheckpoints.autoscaling.k8s.io created
Warning: unrecognized format "int32"
customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalers.autoscaling.k8s.io created

controlplane ~ ‚ûú  kubectl apply -f /root/vpa-rbac.yml
clusterrole.rbac.authorization.k8s.io/system:metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:vpa-actor created
clusterrole.rbac.authorization.k8s.io/system:vpa-status-actor created
clusterrole.rbac.authorization.k8s.io/system:vpa-checkpoint-actor created
clusterrole.rbac.authorization.k8s.io/system:evictioner created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-reader created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-actor created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-status-actor created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-checkpoint-actor created
clusterrole.rbac.authorization.k8s.io/system:vpa-target-reader created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-target-reader-binding created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-evictioner-binding created
serviceaccount/vpa-admission-controller created
serviceaccount/vpa-recommender created
serviceaccount/vpa-updater created
clusterrole.rbac.authorization.k8s.io/system:vpa-admission-controller created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-admission-controller created
clusterrole.rbac.authorization.k8s.io/system:vpa-status-reader created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-status-reader-binding created




3. Clone the VPA Repository and Set Up the Vertical Pod Autoscaler
You are required to clone the Kubernetes Autoscaler repository into the /root directory and set up the Vertical Pod Autoscaler (VPA) by running the provided script.
Steps:
Clone the repository:
First, navigate to the /root directory and clone the repository:
  git clone https://github.com/kubernetes/autoscaler.git
Navigate to the Vertical Pod Autoscaler directory:
After cloning, move into the vertical-pod-autoscaler directory:
   cd autoscaler/vertical-pod-autoscaler
Run the setup script:
Execute the provided script to deploy the Vertical Pod Autoscaler:
   ./hack/vpa-up.sh
By following these steps, the Vertical Pod Autoscaler will be installed and ready to manage pod resources in your Kubernetes cluster.
-----------------------
–ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π VPA –∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ Vertical Pod Autoscaler
–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π Kubernetes Autoscaler –≤ –∫–∞—Ç–∞–ª–æ–≥ /root –∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Vertical Pod Autoscaler (VPA), –∑–∞–ø—É—Å—Ç–∏–≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç.
–®–∞–≥–∏:
–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:
–°–Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –∫–∞—Ç–∞–ª–æ–≥ /root –∏ –∫–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:
   git clone https://github.com/kubernetes/autoscaler.git
–ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –∫–∞—Ç–∞–ª–æ–≥ Vertical Pod Autoscaler:
–ü–æ—Å–ª–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –∫–∞—Ç–∞–ª–æ–≥ vertical-pod-autoscaler:
   cd autoscaler/vertical-pod-autoscaler
–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:
–í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è Vertical Pod Autoscaler:
   ./hack/vpa-up.sh
–í—ã–ø–æ–ª–Ω–∏–≤ —ç—Ç–∏ —à–∞–≥–∏, Vertical Pod Autoscaler –±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—é —Ä–µ—Å—É—Ä—Å–∞–º–∏ –ø–æ–¥–æ–≤ –≤ –≤–∞—à–µ–º –∫–ª–∞—Å—Ç–µ—Ä–µ Kubernetes.


controlplane ~ ‚ûú    git clone https://github.com/kubernetes/autoscaler.git
Cloning into 'autoscaler'...
remote: Enumerating objects: 235987, done.
remote: Counting objects: 100% (1673/1673), done.
remote: Compressing objects: 100% (1160/1160), done.
remote: Total 235987 (delta 1066), reused 513 (delta 513), pack-reused 234314 (from 4)
Receiving objects: 100% (235987/235987), 255.70 MiB | 28.93 MiB/s, done.
Resolving deltas: 100% (153564/153564), done.

controlplane ~ ‚ûú     cd autoscaler/vertical-pod-autoscaler
controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† master via üêπ ‚ûú  

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† master via üêπ ‚ûú     ./hack/vpa-up.sh
HEAD is now at a8ca31655 Merge pull request #8612 from adrianmoisey/vpa-release-1.5
customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalercheckpoints.autoscaling.k8s.io configured
customresourcedefinition.apiextensions.k8s.io/verticalpodautoscalers.autoscaling.k8s.io configured
clusterrole.rbac.authorization.k8s.io/system:metrics-reader unchanged
clusterrole.rbac.authorization.k8s.io/system:vpa-actor configured
clusterrole.rbac.authorization.k8s.io/system:vpa-status-actor unchanged
clusterrole.rbac.authorization.k8s.io/system:vpa-checkpoint-actor unchanged
clusterrole.rbac.authorization.k8s.io/system:evictioner unchanged
clusterrole.rbac.authorization.k8s.io/system:vpa-updater-in-place created
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-updater-in-place-binding created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-reader unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-actor unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-status-actor unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-checkpoint-actor unchanged
clusterrole.rbac.authorization.k8s.io/system:vpa-target-reader unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-target-reader-binding unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-evictioner-binding unchanged
serviceaccount/vpa-admission-controller unchanged
serviceaccount/vpa-recommender unchanged
serviceaccount/vpa-updater unchanged
clusterrole.rbac.authorization.k8s.io/system:vpa-admission-controller configured
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-admission-controller unchanged
clusterrole.rbac.authorization.k8s.io/system:vpa-status-reader unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:vpa-status-reader-binding unchanged
role.rbac.authorization.k8s.io/system:leader-locking-vpa-updater created
rolebinding.rbac.authorization.k8s.io/system:leader-locking-vpa-updater created
role.rbac.authorization.k8s.io/system:leader-locking-vpa-recommender created
rolebinding.rbac.authorization.k8s.io/system:leader-locking-vpa-recommender created
deployment.apps/vpa-updater created
deployment.apps/vpa-recommender created
Generating certs for the VPA Admission Controller in /tmp/vpa-certs.
Certificate request self-signature ok
subject=CN = vpa-webhook.kube-system.svc
Uploading certs to the cluster.
secret/vpa-tls-certs created
Deleting /tmp/vpa-certs.
service/vpa-webhook created
deployment.apps/vpa-admission-controller created
service/vpa-webhook unchanged
[WARN] - (starship::utils): Executing command "git" timed out.
[WARN] - (starship::utils): You can set command_timeout in your config to a higher value to allow longer-running commands to keep executing.



4. Which of the following are the VPA CRDs that get installed as part of the Vertical Pod Autoscaler setup?

- verticalpodautoscaler.autoscaling.k8s.io & horizontalpodautoscalers.autoscaling.k8s.io
- verticalpodautoscalers.autoscaling.k8s.io & verticalpodautoscalercheckpoints.autoscaling.k8s.io <------------
- verticalpodresources.autoscaling.k8s.io & vpa-memory.cpu.k8s.io
- vpa-deployments.autoscaling.k8s.io & vpa-pods.autoscaling.k8s.io

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl get crds | grep verticalpodautoscaler
verticalpodautoscalercheckpoints.autoscaling.k8s.io   2026-01-14T08:35:45Z <------------------------------------
verticalpodautoscalers.autoscaling.k8s.io             2026-01-14T08:35:45Z <------------------------------------

Solution:
To check the installed VPA CRDs, you can use the following commands:
Command to check installed CRDs:
kubectl get crds | grep verticalpodautoscaler
This will list the installed CRDs related to the Vertical Pod Autoscaler, allowing you to verify the correct ones. The expected output should include:
verticalpodautoscalercheckpoints.autoscaling.k8s.io
verticalpodautoscalers.autoscaling.k8s.io



5. How many VPA deployments typically run in the kube-system namespace after installation?

- 6
- 3 <------------ (vpa-admission-controller + vpa-recommender + vpa-updater)
- 4
- 9

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl get deployments.apps -n kube-system
NAME                       READY   UP-TO-DATE   AVAILABLE   AGE
coredns                    2/2     2            2           32m
vpa-admission-controller   1/1     1            1           8m7s
vpa-recommender            1/1     1            1           8m9s
vpa-updater                1/1     1            1           8m9s

Hint:
Check the running service using the below command: kubectl get deployments -n kube-system | grep vpa

Sol:
Components of Vertical Pod Autoscaler (VPA)
The Vertical Pod Autoscaler (VPA) project consists of 3 key components that work together to monitor, recommend, and adjust resource requests for Kubernetes pods. These components include the following:

1. Recommender
Role: The Recommender continuously monitors the current and past resource consumption (CPU and memory) of containers.
Functionality:
Based on the observed usage, it provides recommended values for the containers' CPU and memory requests.
These recommendations are used by the other components to adjust the resource allocations for containers.
Purpose: Ensures that the resource requests of containers are always optimally set based on their actual usage, helping avoid both over-provisioning and under-provisioning of resources.
2. Updater
Role: The Updater is responsible for ensuring that running pods have the correct resource requests as per the Recommender's suggestions.
Functionality:
It checks which of the managed pods have outdated or incorrect resource settings.
If a pod's resources need to be updated, the Updater will evict (terminate) the pod so that it can be recreated by its controller (e.g., Deployment, ReplicaSet) with the updated resource requests.
Purpose: This ensures that the running pods always have the recommended resources by restarting pods with the updated requests if necessary.
3. Admission Plugin
Role: The Admission Plugin sets the correct resource requests on new pods, either when they are first created or when they are recreated due to the Updater's action.
Functionality:
It works during the pod creation process, checking if the pod is managed by VPA.
If the pod is managed by VPA, it modifies the pod's resource requests to reflect the recommended values provided by the Recommender.
Purpose: Ensures that newly created or recreated pods start with the optimal resource requests from the very beginning.
These three components (Recommender, Updater, and Admission Plugin) work together to provide dynamic resource allocation for Kubernetes pods, optimizing resource usage and improving cluster efficiency.
---------------
–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Vertical Pod Autoscaler (VPA)
–ü—Ä–æ–µ–∫—Ç Vertical Pod Autoscaler (VPA) —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 3 –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –ø–æ–¥–æ–≤ Kubernetes. –≠—Ç–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è —Å–ª–µ–¥—É—é—â–µ–µ:
1. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å
–†–æ–ª—å: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –∏ –ø—Ä–æ—à–ª–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ (–¶–ü –∏ –ø–∞–º—è—Ç—å) –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞–º–∏.
–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:
–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–±–ª—é–¥–∞–µ–º–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–Ω –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¶–ü –∏ –ø–∞–º—è—Ç–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤.
–≠—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥—Ä—É–≥–∏–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤.
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –∑–∞–ø—Ä–æ—Å—ã —Ä–µ—Å—É—Ä—Å–æ–≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –≤—Å–µ–≥–¥–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –ø–æ–º–æ–≥–∞—è –∏–∑–±–µ–∂–∞—Ç—å –∫–∞–∫ –∏–∑–±—ã—Ç–æ—á–Ω–æ–≥–æ, —Ç–∞–∫ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤.
2. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ
–†–æ–ª—å: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –ø–æ–¥—ã –ø–æ–ª—É—á–∞–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Ä–µ—Å—É—Ä—Å–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—è.
–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:
–û–Ω –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –∫–∞–∫–∏–µ –∏–∑ —É–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –ø–æ–¥–æ–≤ –∏–º–µ—é—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–µ—Å—É—Ä—Å–æ–≤.
–ï—Å–ª–∏ —Ä–µ—Å—É—Ä—Å—ã –ø–æ–¥–∞ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏, Updater –≤—ã—Ç–µ—Å–Ω–∏—Ç (–∑–∞–≤–µ—Ä—à–∏—Ç —Ä–∞–±–æ—Ç—É) –ø–æ–¥, —á—Ç–æ–±—ã –µ–≥–æ –º–æ–∂–Ω–æ –±—ã–ª–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, Deployment, ReplicaSet) —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏ —Ä–µ—Å—É—Ä—Å–æ–≤.
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –ø–æ–¥—ã –≤—Å–µ–≥–¥–∞ –±—É–¥—É—Ç –∏–º–µ—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã, –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—è –ø–æ–¥—ã —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.
3. –ü–ª–∞–≥–∏–Ω –¥–æ–ø—É—Å–∫–∞
–†–æ–ª—å: –ü–ª–∞–≥–∏–Ω –¥–æ–ø—É—Å–∫–∞ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ–¥–æ–≤ –ª–∏–±–æ –ø—Ä–∏ –∏—Ö –ø–µ—Ä–≤–æ–º —Å–æ–∑–¥–∞–Ω–∏–∏, –ª–∏–±–æ –ø—Ä–∏ –∏—Ö –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –¥–µ–π—Å—Ç–≤–∏–π Updater.
–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:
–û–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–¥–∞, –ø—Ä–æ–≤–µ—Ä—è—è, —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–¥ VPA.
–ï—Å–ª–∏ –ø–æ–¥ —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è VPA, –æ–Ω –∏–∑–º–µ–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å—ã —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ–¥–∞, —á—Ç–æ–±—ã –æ—Ç—Ä–∞–∑–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ Recommender.
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –≤–Ω–æ–≤—å —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø–æ–¥—ã —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞ –±—É–¥—É—Ç –∏–º–µ—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Ä–µ—Å—É—Ä—Å–æ–≤.
–≠—Ç–∏ —Ç—Ä–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ (Recommender, Updater –∏ Admission Plugin) —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –ø–æ–¥–æ–≤ Kubernetes, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –ø–æ–≤—ã—à–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∞.




6. You are given a Kubernetes deployment file named flask-app.yml located in the /root directory. Your task is to:
-Deploy the flask-app.yml file to the Kubernetes cluster
-After deployment, check the logs of the Vertical Pod Autoscaler(VPA) updater to ensure it is functioning correctly
-Note: The pod may take some time to reach the running state.

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl apply -f /root/flask-app.yml
deployment.apps/flask-app created
service/flask-app-service created
verticalpodautoscaler.autoscaling.k8s.io/flask-app created

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl get deployments.apps 
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
flask-app   1/1     1            1           86s

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl logs pods/vpa-updater-6cf6bc7ff8-zxkkt -n kube-system
E0114 08:59:05.072232       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/etcd-controlplane"
E0114 08:59:05.072268       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-apiserver-controlplane"
E0114 08:59:05.072278       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-controller-manager-controlplane"
E0114 08:59:05.072287       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-scheduler-controlplane"
I0114 08:59:05.072317       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2











7. You have recently deployed a Flask application to your Kubernetes cluster. However, the Vertical Pod Autoscaler (VPA) vpa-updater-XXXX pod indicates that there may be an issue with the newly deployed flask-app pods.
Inspect the logs of the vpa-updater-XXXX pod and observe the following message:
Check the logs of the vpa-updater-XXXX pod to identify any potential issues with the flask-app deployment.
When checking the logs, you see the following error message:
    [pods_eviction_restriction.go:226] **too few replicas** for **ReplicaSet** default/**flask-app-b6c9c4f78**
Problem Analysis:
Flask application is running with only 1 replica pod.
The Vertical Pod Autoscaler (VPA) needs to evict (remove) the existing pod to create a new one with updated resource settings.
Kubernetes has a safety feature that prevents removing the last pod of a deployment to avoid service downtime.
When you have only 1 replica and VPA tries to evict it, Kubernetes blocks this action with the error message: "too few replicas".
VPA wants to optimize your pod's resources but cannot because Kubernetes is protecting your service availability.
As a result, VPA cannot apply its resource recommendations, and application cannot benefit from automatic resource optimization.
Approach to Resolve the Issue:
1. Increase the replica count:
    kubectl scale deployment flask-app --replicas=2
2. Verify the Deployment:
    kubectl get deployment flask-app -o wide
Ensure that the DESIRED column shows the updated replica count, and the CURRENT column matches the desired number.
3. Check the Pod Status:
    kubectl get pods -l app=flask-app
Wait until all pods show Running status.
You should see two pods (or more) in a Running state.
4. Verify VPA operation:
    kubectl describe vpa flask-app
This will show the current state of the VPA and any recommendations it has made. If it's working properly, you should see resource recommendations (for CPU and memory) in the output.
With 2 replicas, Kubernetes can safely remove one pod while keeping your application running, allowing VPA to work properly.
--------------------------------
–í—ã –Ω–µ–¥–∞–≤–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É–ª–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Flask –≤ —Å–≤–æ–µ–º –∫–ª–∞—Å—Ç–µ—Ä–µ Kubernetes. –û–¥–Ω–∞–∫–æ –ø–æ–¥ Vertical Pod Autoscaler (VPA) vpa-updater-XXXX —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –≤–æ–∑–º–æ–∂–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É —Å –Ω–µ–¥–∞–≤–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–º–∏ –ø–æ–¥–∞–º–∏ flask-app.
–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –ø–æ–¥–∞ vpa-updater-XXXX –∏ –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:
–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –ø–æ–¥–∞ vpa-updater-XXXX, —á—Ç–æ–±—ã –≤—ã—è–≤–∏—Ç—å –ª—é–±—ã–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ–º flask-app.
–ü—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ª–æ–≥–æ–≤ –≤—ã –≤–∏–¥–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ:

[pods_eviction_restriction.go:226] **—Å–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ä–µ–ø–ª–∏–∫** –¥–ª—è **ReplicaSet** default/**flask-app-b6c9c4f78**
–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º—ã:
–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ Flask —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å 1 —Ä–µ–ø–ª–∏–∫–æ–π –ø–æ–¥–∞.

–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –ø–æ–¥–∞ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —Ä–µ—Å—É—Ä—Å–æ–≤ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–º—É –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é –ø–æ–¥–æ–≤ (VPA) –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–¥–∞–ª–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–æ–¥.
Kubernetes –∏–º–µ–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–¥–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –≤–æ –∏–∑–±–µ–∂–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ—è —Å–µ—Ä–≤–∏—Å–∞.
–ï—Å–ª–∏ —É –≤–∞—Å –≤—Å–µ–≥–æ 1 —Ä–µ–ø–ª–∏–∫–∞, –∏ VPA –ø—ã—Ç–∞–µ—Ç—Å—è –µ—ë —É–¥–∞–ª–∏—Ç—å, Kubernetes –±–ª–æ–∫–∏—Ä—É–µ—Ç —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ–± –æ—à–∏–±–∫–µ: ¬´—Å–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ä–µ–ø–ª–∏–∫¬ª.
VPA —Ö–æ—á–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—Å—É—Ä—Å—ã –≤–∞—à–µ–≥–æ –ø–æ–¥–∞, –Ω–æ –Ω–µ –º–æ–∂–µ—Ç, –ø–æ—Å–∫–æ–ª—å–∫—É Kubernetes –∑–∞—â–∏—â–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤–∞—à–µ–≥–æ —Å–µ—Ä–≤–∏—Å–∞.
–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ VPA –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Å–≤–æ–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ—Å—É—Ä—Å–∞–º, –∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞–º–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤.
–ü–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º—ã:
1. –£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–ª–∏–∫:
    kubectl scale deployment flask-app --replicas=2
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ:
    kubectl get deployment flask-app -o wide
–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ —Å—Ç–æ–ª–±—Ü–µ DESIRED –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–ª–∏–∫, –∞ –≤ —Å—Ç–æ–ª–±—Ü–µ CURRENT ‚Äî –∂–µ–ª–∞–µ–º–æ–µ —á–∏—Å–ª–æ.
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å –ø–æ–¥–∞:
    kubectl get pods -l app=flask-app
–î–æ–∂–¥–∏—Ç–µ—Å—å, –ø–æ–∫–∞ –≤—Å–µ –ø–æ–¥—ã –Ω–µ –æ—Ç–æ–±—Ä–∞–∑—è—Ç —Å—Ç–∞—Ç—É—Å Running.
–í—ã –¥–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å –¥–≤–∞ (–∏–ª–∏ –±–æ–ª–µ–µ) –ø–æ–¥–∞ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ Running.
4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É VPA:
    kubectl describe vpa flask-app
–≠—Ç–æ –ø–æ–∫–∞–∂–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ VPA –∏ –ª—é–±—ã–µ —Å–¥–µ–ª–∞–Ω–Ω—ã–µ –∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏. –ï—Å–ª–∏ –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –≤—ã –¥–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ—Å—É—Ä—Å–∞–º (–¥–ª—è –¶–ü –∏ –ø–∞–º—è—Ç–∏) –≤ –≤—ã–≤–æ–¥–µ.
–ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ 2 —Ä–µ–ø–ª–∏–∫ Kubernetes –º–æ–∂–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ —É–¥–∞–ª–∏—Ç—å –æ–¥–∏–Ω –ø–æ–¥, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º —Ä–∞–±–æ—Ç—É –≤–∞—à–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —á—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç VPA —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.

trolplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚úñ kubectl logs pods/vpa-updater-6cf6bc7ff8-zxkkt -n kube-system | grep -i flask-app 
[I0114 08:55:05.072398       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
[I0114 08:56:05.072727       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
[I0114 08:57:05.072099       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
[I0114 08:58:05.072723       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
[I0114 08:59:05.072317       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
[I0114 09:00:05.074894       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
[I0114 09:01:05.072861       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
[I0114 09:02:05.073206       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2





controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl scale deployment flask-app --replicas=2
deployment.apps/flask-app scaled

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl get deployment flask-app -o wide
NAME        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                          SELECTOR
flask-app   2/2     2            2           10m   flask-app    kodekloud/flask-session-app:1   app=flask-app

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl get pods -l app=flask-app
NAME                         READY   STATUS    RESTARTS   AGE
flask-app-84d5df7d4c-bclsb   1/1     Running   0          10m
flask-app-84d5df7d4c-f7th4   1/1     Running   0          22s

controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl describe vpa flask-app
Name:         flask-app
Namespace:    default
Labels:       <none>
Annotations:  <none>
API Version:  autoscaling.k8s.io/v1
Kind:         VerticalPodAutoscaler
Metadata:
  Creation Timestamp:  2026-01-14T08:54:12Z
  Generation:          1
  Resource Version:    3899
  UID:                 cef304a5-79c0-4fb4-9f43-6c215038181d
Spec:
  Resource Policy:
    Container Policies:
      Container Name:  *
      Controlled Resources:
        cpu
        memory
      Max Allowed:
        Cpu:     1
        Memory:  500Mi
      Min Allowed:
        Cpu:     100m
        Memory:  100Mi
  Target Ref:
    API Version:  apps/v1
    Kind:         Deployment
    Name:         flask-app
  Update Policy:
    Eviction Requirements:
      Change Requirement:  TargetHigherThanRequests
      Resources:
        cpu
        memory
    Update Mode:  Recreate
Status:
  Conditions:
    Last Transition Time:  2026-01-14T08:55:05Z
    Status:                True
    Type:                  RecommendationProvided
  Recommendation:
    Container Recommendations:
      Container Name:  flask-app
      Lower Bound:
        Cpu:     100m
        Memory:  250Mi
      Target:
        Cpu:     100m
        Memory:  250Mi
      Uncapped Target:
        Cpu:     25m
        Memory:  250Mi
      Upper Bound:
        Cpu:     100m
        Memory:  250Mi
Events:
  Type    Reason      Age   From         Message
  ----    ------      ----  ----         -------
  Normal  EvictedPod  7s    vpa-updater  VPA Updater evicted Pod flask-app-84d5df7d4c-bclsb to apply resource recommendation.

Solution:
Here is a command that picks the name of the vpa-updater pod and prints its logs:
    kubectl logs $(kubectl get pods -n kube-system --no-headers -o custom-columns=":metadata.name" | grep vpa-updater) -n kube-system

    controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kkubectl get pods -n kube-system --no-headers -o custom-columns=":metadata.name" | grep vpa-updater
vpa-updater-6cf6bc7ff8-t9m6x

This command first retrieves the pod name using kubectl get pods and then pipes it to the kubectl logs command to print the logs of the vpa-updater pod.
You will see output similar to this:

[pods_eviction_restriction.go:226] too few replicas for ReplicaSet default/flask-app-b6c9c4f78. Found 1 live pods, needs 2 (global 2)



controlplane autoscaler/vertical-pod-autoscaler on ÓÇ† HEAD (a8ca316) via üêπ ‚ûú  kubectl logs $(kubectl get pods -n kube-system --no-headers -o custom-columns=":metadata.name" | grep vpa-updater) -n kube-system
I0114 09:08:55.694975       1 flags.go:57] FLAG: --add-dir-header="false"
I0114 09:08:55.695110       1 flags.go:57] FLAG: --address=":8943"
I0114 09:08:55.695115       1 flags.go:57] FLAG: --alsologtostderr="false"
I0114 09:08:55.695120       1 flags.go:57] FLAG: --evict-after-oom-threshold="10m0s"
I0114 09:08:55.695124       1 flags.go:57] FLAG: --eviction-rate-burst="1"
I0114 09:08:55.695128       1 flags.go:57] FLAG: --eviction-rate-limit="-1"
I0114 09:08:55.695132       1 flags.go:57] FLAG: --eviction-tolerance="0.5"
I0114 09:08:55.695136       1 flags.go:57] FLAG: --feature-gates=""
I0114 09:08:55.695143       1 flags.go:57] FLAG: --ignored-vpa-object-namespaces=""
I0114 09:08:55.695146       1 flags.go:57] FLAG: --in-recommendation-bounds-eviction-lifetime-threshold="12h0m0s"
I0114 09:08:55.695149       1 flags.go:57] FLAG: --kube-api-burst="100"
I0114 09:08:55.695153       1 flags.go:57] FLAG: --kube-api-qps="50"
I0114 09:08:55.695157       1 flags.go:57] FLAG: --kubeconfig=""
I0114 09:08:55.695160       1 flags.go:57] FLAG: --leader-elect="false"
I0114 09:08:55.695165       1 flags.go:57] FLAG: --leader-elect-lease-duration="15s"
I0114 09:08:55.695170       1 flags.go:57] FLAG: --leader-elect-renew-deadline="10s"
I0114 09:08:55.695173       1 flags.go:57] FLAG: --leader-elect-resource-lock="leases"
I0114 09:08:55.695179       1 flags.go:57] FLAG: --leader-elect-resource-name="vpa-updater"
I0114 09:08:55.695182       1 flags.go:57] FLAG: --leader-elect-resource-namespace="kube-system"
I0114 09:08:55.695186       1 flags.go:57] FLAG: --leader-elect-retry-period="2s"
I0114 09:08:55.695190       1 flags.go:57] FLAG: --log-backtrace-at=":0"
I0114 09:08:55.695198       1 flags.go:57] FLAG: --log-dir=""
I0114 09:08:55.695215       1 flags.go:57] FLAG: --log-file=""
I0114 09:08:55.695231       1 flags.go:57] FLAG: --log-file-max-size="1800"
I0114 09:08:55.695235       1 flags.go:57] FLAG: --logtostderr="true"
I0114 09:08:55.695238       1 flags.go:57] FLAG: --min-replicas="2"
I0114 09:08:55.695242       1 flags.go:57] FLAG: --one-output="false"
I0114 09:08:55.695245       1 flags.go:57] FLAG: --pod-update-threshold="0.1"
I0114 09:08:55.695249       1 flags.go:57] FLAG: --profiling="false"
I0114 09:08:55.695253       1 flags.go:57] FLAG: --skip-headers="false"
I0114 09:08:55.695256       1 flags.go:57] FLAG: --skip-log-headers="false"
I0114 09:08:55.695260       1 flags.go:57] FLAG: --stderrthreshold="0"
I0114 09:08:55.695263       1 flags.go:57] FLAG: --updater-interval="1m0s"
I0114 09:08:55.695267       1 flags.go:57] FLAG: --use-admission-controller-status="true"
I0114 09:08:55.695271       1 flags.go:57] FLAG: --v="4"
I0114 09:08:55.695275       1 flags.go:57] FLAG: --vmodule=""
I0114 09:08:55.695279       1 flags.go:57] FLAG: --vpa-object-namespace=""
I0114 09:08:55.695300       1 main.go:99] "Vertical Pod Autoscaler Updater" version="1.5.1"
I0114 09:08:55.695653       1 envvar.go:172] "Feature gate default state" feature="InOrderInformers" enabled=true
I0114 09:08:55.695667       1 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false
I0114 09:08:55.695674       1 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false
I0114 09:08:55.695683       1 envvar.go:172] "Feature gate default state" feature="ClientsAllowCBOR" enabled=false
I0114 09:08:55.695688       1 envvar.go:172] "Feature gate default state" feature="ClientsPreferCBOR" enabled=false
I0114 09:08:55.696435       1 reflector.go:358] "Starting reflector" type="*v1.CronJob" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.696449       1 reflector.go:404] "Listing and watching" type="*v1.CronJob" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.696447       1 reflector.go:358] "Starting reflector" type="*v1.ReplicationController" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.696468       1 reflector.go:404] "Listing and watching" type="*v1.ReplicationController" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.697996       1 reflector.go:358] "Starting reflector" type="*v1.StatefulSet" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698016       1 reflector.go:358] "Starting reflector" type="*v1.ReplicaSet" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698026       1 reflector.go:404] "Listing and watching" type="*v1.StatefulSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698054       1 reflector.go:404] "Listing and watching" type="*v1.ReplicaSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698240       1 reflector.go:358] "Starting reflector" type="*v1.DaemonSet" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698267       1 reflector.go:404] "Listing and watching" type="*v1.DaemonSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698353       1 reflector.go:358] "Starting reflector" type="*v1.Job" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698378       1 reflector.go:404] "Listing and watching" type="*v1.Job" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698278       1 reflector.go:358] "Starting reflector" type="*v1.LimitRange" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698434       1 reflector.go:404] "Listing and watching" type="*v1.LimitRange" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698520       1 reflector.go:358] "Starting reflector" type="*v1.Deployment" resyncPeriod="10m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.698560       1 reflector.go:404] "Listing and watching" type="*v1.Deployment" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.890204       1 reflector.go:436] "Caches populated" type="*v1.Job" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.890364       1 reflector.go:436] "Caches populated" type="*v1.LimitRange" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.890217       1 reflector.go:436] "Caches populated" type="*v1.StatefulSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.890483       1 reflector.go:436] "Caches populated" type="*v1.DaemonSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.896952       1 reflector.go:436] "Caches populated" type="*v1.CronJob" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.897274       1 reflector.go:436] "Caches populated" type="*v1.ReplicationController" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.897847       1 reflector.go:436] "Caches populated" type="*v1.ReplicaSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.898485       1 reflector.go:436] "Caches populated" type="*v1.Deployment" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.996992       1 updater.go:350] "Rate limit disabled"
I0114 09:08:55.997034       1 updater.go:350] "Rate limit disabled"
I0114 09:08:55.997119       1 reflector.go:358] "Starting reflector" type="*v1.ReplicationController" resyncPeriod="1m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.997131       1 reflector.go:404] "Listing and watching" type="*v1.ReplicationController" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:55.998770       1 reflector.go:436] "Caches populated" type="*v1.ReplicationController" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.098330       1 reflector.go:358] "Starting reflector" type="*v1.StatefulSet" resyncPeriod="1m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.098362       1 reflector.go:404] "Listing and watching" type="*v1.StatefulSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.100340       1 reflector.go:436] "Caches populated" type="*v1.StatefulSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.198828       1 reflector.go:358] "Starting reflector" type="*v1.ReplicaSet" resyncPeriod="1m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.198880       1 reflector.go:404] "Listing and watching" type="*v1.ReplicaSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.201097       1 reflector.go:436] "Caches populated" type="*v1.ReplicaSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.299292       1 reflector.go:358] "Starting reflector" type="*v1.DaemonSet" resyncPeriod="1m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.299344       1 reflector.go:404] "Listing and watching" type="*v1.DaemonSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.301855       1 reflector.go:436] "Caches populated" type="*v1.DaemonSet" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.399791       1 reflector.go:358] "Starting reflector" type="*v1.VerticalPodAutoscaler" resyncPeriod="1h0m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.399846       1 reflector.go:404] "Listing and watching" type="*v1.VerticalPodAutoscaler" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.402575       1 reflector.go:436] "Caches populated" type="*v1.VerticalPodAutoscaler" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.500254       1 api.go:105] "Initial VPA synced successfully"
I0114 09:08:56.500479       1 reflector.go:358] "Starting reflector" type="*v1.Pod" resyncPeriod="1h0m0s" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.500505       1 reflector.go:404] "Listing and watching" type="*v1.Pod" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:08:56.519082       1 reflector.go:436] "Caches populated" type="*v1.Pod" reflector="pkg/mod/k8s.io/client-go@v0.34.0/tools/cache/reflector.go:290"
I0114 09:09:56.508723       1 updater.go:194] "No VPA objects to process"
E0114 09:10:56.509216       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-apiserver-controlplane"
E0114 09:10:56.509244       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-scheduler-controlplane"
E0114 09:10:56.509270       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/etcd-controlplane"
E0114 09:10:56.509278       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-controller-manager-controlplane"
I0114 09:10:56.509334       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2
E0114 09:11:56.509522       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-controller-manager-controlplane"
E0114 09:11:56.509580       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-apiserver-controlplane"
E0114 09:11:56.509593       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/kube-scheduler-controlplane"
E0114 09:11:56.509616       1 api.go:175] "Failed to get parent controller for pod" err="unhandled targetRef v1 / Node / controlplane, last error node is not a valid owner" pod="kube-system/etcd-controlplane"
I0114 09:11:56.509670       1 pods_restriction_factory.go:212] "Too few replicas" kind="ReplicaSet" object="default/flask-app-84d5df7d4c" livePods=1 requiredPods=2 globalMinReplicas=2